
<html>

    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
        <title>Robust Representation Similarity</title>
    
        <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
        <script type="text/javascript" src="jquery.mlens-1.0.min.js"></script>
        <script type="text/javascript" src="jquery.js"></script>
        <style>
            body {
                font-family: 'Open-Sans', sans-serif;
                font-weight: 300;
                background-color: #fff;
            }
    
            .content {
                width: 1000px;
                padding: 25px 50px;
                margin: 25px auto;
                background-color: white;
                box-shadow: 0px 0px 10px #999;
                border-radius: 15px;
            }
    
            .contentblock {
                width: 950px;
                margin: 0 auto;
                padding: 0;
                border-spacing: 25px 0;
            }
    
            .contentblock td {
                background-color: #fff;
                padding: 25px 50px;
                vertical-align: top;
                box-shadow: 0px 0px 10px #999;
                border-radius: 15px;
            }
    
            a,
            a:visited {
                color: #224b8d;
                font-weight: 300;
            }
    
            .authors {
                text-align: center;
                margin-bottom: 20px;
                /* display: flexbox; */
            }
    
            #conference {
                text-align: center;
                margin-bottom: 20px;
                font-style: italic;
            }
    
            .authors a {
                margin: 0 10px;
            }
    
            h1 {
                text-align: center;
                font-size: 35px;
                font-weight: 300;
            }
    
            h2 {
                font-size: 30px;
                font-weight: 300;
            }
    
            code {
                display: block;
                padding: 10px;
                margin: 10px 10px;
            }
    
            p {
                line-height: 25px;
                text-align: justify;
            }
    
            p code {
                display: inline;
                padding: 0;
                margin: 0;
            }
    
            #teasers {
                margin: 0 auto;
            }
    
            #teasers td {
                margin: 0 auto;
                text-align: center;
                padding: 5px;
            }
    
            #teasers img {
                width: 250px;
            }
    
            #results img {
                width: 133px;
            }
    
            #seeintodark {
                margin: 0 auto;
            }
    
            #sift {
                margin: 0 auto;
            }
    
            #sift img {
                width: 250px;
            }
    
            .downloadpaper {
                padding-left: 20px;
                float: right;
                text-align: center;
            }
    
            .downloadpaper a {
                font-weight: bold;
                text-align: center;
            }
    
            #demoframe {
                border: 0;
                padding: 0;
                margin: 0;
                width: 100%;
                height: 340px;
            }
    
            #feedbackform {
                border: 1px solid #ccc;
                margin: 0 auto;
                border-radius: 15px;
            }
    
            #eyeglass {
                height: 530px;
            }
    
            #eyeglass #wrapper {
                position: relative;
                height: auto;
                margin: 0 auto;
                float: left;
                width: 800px;
            }
    
            #mitnews {
                font-weight: normal;
                margin-top: 20px;
                font-size: 14px;
                width: 220px;
            }
    
            #mitnews a {
                font-weight: normal;
            }
    
            .teaser-img {
                width: 100%;
            }
    
            .iframe {
                width: 100%;
                height: 125%
            }
        </style>
        <!-- Global site tag (gtag.js) - Google Analytics -->
            <!--
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-98008272-2"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
    
            function gtag() {
                dataLayer.push(arguments);
            }
            gtag('js', new Date());
            gtag('config', 'UA-98008272-2');
        </script>
        <script type="text/javascript" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
        </script>
            -->
    
    </head>
    
    <body>
    
        <div class="content">
            <h1>Understanding Robust Learning through the Lens of Representation Similarities</h1>
    
            <p class="authors">
                <a href="https://cs.uchicago.edu/people/christian-cianfarani/">Christian Cianfarani*<sup>1</sup></a>
                <a href="https://arjunbhagoji.github.io/">Arjun Nitin Bhagoji*<sup>1</sup></a>
                <a href="https://vsehwag.github.io/"> Vikash Sehwag*<sup>2</sup></a><br>
                <a href="https://people.cs.uchicago.edu/~ravenben/"> Ben Y. Zhao<sup>1</sup></a><br>
                <a href="https://www.princeton.edu/~pmittal/"> Prateek Mittal<sup>2</sup></a><br>
                <a href="https://people.cs.uchicago.edu/~htzheng/"> Haitao Zheng<sup>1</sup></a><br>
                <sup>1</sup>University of Chicago, <sup>2</sup>Princeton University
            </p>
            <font size="+2">
                <p style="text-align: center;">
                    <a href="https://arxiv.org/abs/2206.09868" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
                    <!-- <a href="files/poster.pdf" target="_blank">[Poster]</a> &nbsp;&nbsp;&nbsp;&nbsp; -->
                    <a href="https://github.com/inspire-group/robust_representation_similarity" target="_blank">[Code]</a> &nbsp;&nbsp;&nbsp;&nbsp;
                    <!-- <a href="https://youtu.be/nS0V64sF7Cw" target="_blank">[Video]</a> -->
                </p>
                </font>
            <p>
                <img class='teaser-img' src='assets/block_structure.png'></img>
            </p>
                    <!--
            <div class="downloadpaper">
                <br>
                <a href="https://arxiv.org/pdf/1907.07171.pdf"><img src="img/cover.png" width="160px" border="2">
                    <p style="text-align: center;">
                        <a href="https://arxiv.org/pdf/1907.07171.pdf" target="_blank">[Paper]</a> 
                        <a href="https://github.com/ali-design/gan_steerability" target="_blank">[Code]</a>
                    </p>
            </div>
                    -->
    
            <p>Representation learning, i.e. the generation of representations useful for downstream applications, is a task of fundamental importance that underlies much of the success of deep
                neural networks (DNNs). Recently, robustness to adversarial examples has emerged as a
                desirable property for DNNs, spurring the development of robust training methods that
                account for adversarial examples. In this paper, we aim to understand how the properties of
                representations learned by robust training differ from those obtained from standard, nonrobust training. This is critical to diagnosing numerous salient pitfalls in robust networks,
                such as, degradation of performance on benign inputs, poor generalization of robustness, and
                increase in over-fitting. We utilize a powerful set of tools known as representation similarity
                metrics, across three vision datasets, to obtain layer-wise comparisons between robust and
                non-robust DNNs with different training procedures, architectural parameters and adversarial
                constraints. Our experiments highlight hitherto unseen properties of robust representations
                that we posit underlie the behavioral differences of robust networks. We discover a lack
                of specialization in robust networks' representations along with a disappearance of <emph>block
                structure</emph>. We also find overfitting during robust training largely impacts deeper layers.
                These, along with other findings, suggest ways forward for the design and training of better
                robust networks.</p>
    
    
            <br clear="all">
        </div>
        <!-- <div class="content" id="video">
                    <font size="+2">
                        <p style="text-align: center;">
                            Links to: &nbsp;&nbsp;
                            <a href="https://arxiv.org/abs/1907.07171" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
                            <a href="files/poster.pdf" target="_blank">[Poster]</a> &nbsp;&nbsp;&nbsp;&nbsp;
                            <a href="https://github.com/ali-design/gan_steerability" target="_blank">[Code]</a> &nbsp;&nbsp;&nbsp;&nbsp;
                            <a href="https://youtu.be/nS0V64sF7Cw" target="_blank">[Video]</a>
                        </p>
                        <p style="text-align: center;">
                        <iframe width="970" height="550" src="https://www.youtube.com/embed/nS0V64sF7Cw?start=2" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        </p>
                        </font>
        </div> -->
        <div class="content" id="references">
    
            <h2>Reference</h2>
    
            <!-- <p>A. Jahanian*, L. Chai*, and P. Isola. On the "steerability" of generative adversarial networks. 2020.</p> -->
    
            <code>
            @inproceedings{robustrs,<br>
                &nbsp;&nbsp;title={Understanding Robust Learning through the Lens of Representation Similarities},<br>
                &nbsp;&nbsp;author={Cianfarani, Christian and Bhagoji, Arjun Nitin and Sehwag, Vikash and Zhao, Ben Y. and Mittal, Prateek and Zheng, Haitao},<br>
                &nbsp;&nbsp;booktitle={Conference on Neural Information Processing Systems (NeurIPS)},<br>
                &nbsp;&nbsp;year={2022}<br>
                }
            </code>
    
        </div>      
        <div class="content" id="acknowledgements">
              <p><strong>Acknowledgements</strong>: <br>
                  <!-- This work was supported by a Google Faculty Research Award to P.I., and a U.S. National Science Foundation Graduate Research Fellowship to L.C.  -->
                  Website template is borrowed from following <a href="https://ali-design.github.io/gan_steerability/">source</a>.
                  <!--
                  <p><strong>Disclaimer</strong>: The views and conclusions contained herein are those of the authors and
                      should not be interpreted as necessarily representing the official policies or endorsements, either
                      expressed or implied, of IARPA, DOI/IBC, or the U.S.
                  </p>
                  -->
        </div>
    </body>
    
    </html>
    
